{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "url = \"https://api.github.com/repos/huggingface/datasets/issues?page=1&per_page=1\"\n",
    "response = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'url': 'https://api.github.com/repos/huggingface/datasets/issues/6353',\n",
       "  'repository_url': 'https://api.github.com/repos/huggingface/datasets',\n",
       "  'labels_url': 'https://api.github.com/repos/huggingface/datasets/issues/6353/labels{/name}',\n",
       "  'comments_url': 'https://api.github.com/repos/huggingface/datasets/issues/6353/comments',\n",
       "  'events_url': 'https://api.github.com/repos/huggingface/datasets/issues/6353/events',\n",
       "  'html_url': 'https://github.com/huggingface/datasets/issues/6353',\n",
       "  'id': 1962646450,\n",
       "  'node_id': 'I_kwDODunzps50-5uy',\n",
       "  'number': 6353,\n",
       "  'title': 'load_dataset save_to_disk load_from_disk error',\n",
       "  'user': {'login': 'brisker',\n",
       "   'id': 13804492,\n",
       "   'node_id': 'MDQ6VXNlcjEzODA0NDky',\n",
       "   'avatar_url': 'https://avatars.githubusercontent.com/u/13804492?v=4',\n",
       "   'gravatar_id': '',\n",
       "   'url': 'https://api.github.com/users/brisker',\n",
       "   'html_url': 'https://github.com/brisker',\n",
       "   'followers_url': 'https://api.github.com/users/brisker/followers',\n",
       "   'following_url': 'https://api.github.com/users/brisker/following{/other_user}',\n",
       "   'gists_url': 'https://api.github.com/users/brisker/gists{/gist_id}',\n",
       "   'starred_url': 'https://api.github.com/users/brisker/starred{/owner}{/repo}',\n",
       "   'subscriptions_url': 'https://api.github.com/users/brisker/subscriptions',\n",
       "   'organizations_url': 'https://api.github.com/users/brisker/orgs',\n",
       "   'repos_url': 'https://api.github.com/users/brisker/repos',\n",
       "   'events_url': 'https://api.github.com/users/brisker/events{/privacy}',\n",
       "   'received_events_url': 'https://api.github.com/users/brisker/received_events',\n",
       "   'type': 'User',\n",
       "   'site_admin': False},\n",
       "  'labels': [],\n",
       "  'state': 'open',\n",
       "  'locked': False,\n",
       "  'assignee': None,\n",
       "  'assignees': [],\n",
       "  'milestone': None,\n",
       "  'comments': 0,\n",
       "  'created_at': '2023-10-26T03:47:06Z',\n",
       "  'updated_at': '2023-10-26T03:59:20Z',\n",
       "  'closed_at': None,\n",
       "  'author_association': 'NONE',\n",
       "  'active_lock_reason': None,\n",
       "  'body': '### Describe the bug\\r\\n\\r\\ndatasets version： 2.10.1\\r\\nI `load_dataset `and `save_to_disk` sucessfully on windows10( **and I `load_from_disk(/LLM/data/wiki)` succcesfully on windows10**), and I copy the dataset `/LLM/data/wiki`\\r\\ninto a ubuntu system, but when I `load_from_disk(/LLM/data/wiki)` on ubuntu,  something weird happens:\\r\\n\\r\\n\\r\\n```\\r\\nload_from_disk(\\'/LLM/data/wiki\\')\\r\\n  File \"/usr/local/miniconda3/lib/python3.8/site-packages/datasets/load.py\", line 1874, in load_from_disk\\r\\n    return DatasetDict.load_from_disk(dataset_path, keep_in_memory=keep_in_memory, storage_options=storage_options)\\r\\n  File \"/usr/local/miniconda3/lib/python3.8/site-packages/datasets/dataset_dict.py\", line 1309, in load_from_disk\\r\\n    dataset_dict[k] = Dataset.load_from_disk(\\r\\n  File \"/usr/local/miniconda3/lib/python3.8/site-packages/datasets/arrow_dataset.py\", line 1543, in load_from_disk\\r\\n    fs_token_paths = fsspec.get_fs_token_paths(dataset_path, storage_options=storage_options)\\r\\n  File \"/usr/local/miniconda3/lib/python3.8/site-packages/fsspec/core.py\", line 610, in get_fs_token_paths\\r\\n    chain = _un_chain(urlpath0, storage_options or {})\\r\\n  File \"/usr/local/miniconda3/lib/python3.8/site-packages/fsspec/core.py\", line 325, in _un_chain\\r\\n    cls = get_filesystem_class(protocol)\\r\\n  File \"/usr/local/miniconda3/lib/python3.8/site-packages/fsspec/registry.py\", line 232, in get_filesystem_class\\r\\n    raise ValueError(f\"Protocol not known: {protocol}\")\\r\\nValueError: Protocol not known: /LLM/data/wiki\\r\\n```\\r\\nIt seems that something went wrong on the arrow file?\\r\\nHow can I solve this , since currently I can not save_to_disk on ubuntu system\\r\\n\\r\\n### Steps to reproduce the bug\\r\\n\\r\\ndatasets version： 2.10.1\\r\\n\\r\\n### Expected behavior\\r\\n\\r\\ndatasets version： 2.10.1\\r\\n\\r\\n### Environment info\\r\\n\\r\\ndatasets version： 2.10.1',\n",
       "  'reactions': {'url': 'https://api.github.com/repos/huggingface/datasets/issues/6353/reactions',\n",
       "   'total_count': 0,\n",
       "   '+1': 0,\n",
       "   '-1': 0,\n",
       "   'laugh': 0,\n",
       "   'hooray': 0,\n",
       "   'confused': 0,\n",
       "   'heart': 0,\n",
       "   'rocket': 0,\n",
       "   'eyes': 0},\n",
       "  'timeline_url': 'https://api.github.com/repos/huggingface/datasets/issues/6353/timeline',\n",
       "  'performed_via_github_app': None,\n",
       "  'state_reason': None}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "GITHUB_TOKEN = \"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\"\n",
    "headers = {\"Authorization\": f\"token {GITHUB_TOKEN}\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "def fetch_issues(\n",
    "    owner=\"huggingface\",\n",
    "    repo=\"datasets\",\n",
    "    num_issues=10_000,\n",
    "    rate_limit=5_000,\n",
    "    issues_path=Path(\".\"),\n",
    "):\n",
    "    if not issues_path.is_dir():\n",
    "        issues_path.mkdir(exist_ok=True)\n",
    "\n",
    "    batch = []\n",
    "    all_issues = []\n",
    "    per_page = 10  # Number of issues to return per page\n",
    "    num_pages = math.ceil(num_issues / per_page)\n",
    "    base_url = \"https://api.github.com/repos\"\n",
    "\n",
    "    for page in tqdm(range(num_pages)):\n",
    "        # Query with state=all to get both open and closed issues\n",
    "        query = f\"issues?page={page}&per_page={per_page}&state=all\"\n",
    "        issues = requests.get(f\"{base_url}/{owner}/{repo}/{query}\", headers=headers)\n",
    "        batch.extend(issues.json())\n",
    "\n",
    "        # if len(batch) > rate_limit and len(all_issues) < num_issues:\n",
    "        #     all_issues.extend(batch)\n",
    "        #     batch = []  # Flush batch for next time period\n",
    "        #     print(f\"Reached GitHub rate limit. Sleeping for one hour ...\")\n",
    "        #     time.sleep(60 * 60 + 1)\n",
    "\n",
    "    all_issues.extend(batch)\n",
    "    df = pd.DataFrame.from_records(all_issues)\n",
    "    df.to_json(f\"{issues_path}/{repo}-issues.jsonl\", orient=\"records\", lines=True)\n",
    "    print(\n",
    "        f\"Downloaded all the issues for {repo}! Dataset stored at {issues_path}/{repo}-issues.jsonl\"\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
